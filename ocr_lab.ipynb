{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image_file = \"img//test1.png\"\n",
    "output_image_file=\"img//test1_processed.png\"\n",
    "resized_image_file=\"img//test1_resized.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noisy table with bigger dots saved as img\\test1.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "def generate_greyscale_color():\n",
    "    grey_value = random.randint(0, 255)\n",
    "    return (grey_value, grey_value, grey_value)\n",
    "\n",
    "\n",
    "# Create a DataFrame with random values and variable-length strings\n",
    "data = {\n",
    "    'col1':['/'.join([str(random.randint(1000000000, 9000000000)), str(random.randint(10000000, 90000000))]) for _ in range(50)],\n",
    "    'col2': np.random.randint(0, 100, 50),\n",
    "    'col3': [''.join(random.choices('abcdefghijklmnopqrstuvwxyz', k=random.randint(5, 15))) for _ in range(50)],\n",
    "    'col4': np.random.randint(100000000, 900000000, 50),\n",
    "    'col5': [random.choice(['A', 'B', 'C', 'D']) for _ in range(50)]\n",
    "}\n",
    "\n",
    "df_dummy = pd.DataFrame(data)\n",
    "\n",
    "# Convert the table to an image\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "table = ax.table(cellText=df_dummy.values, colLabels=df_dummy.columns, cellLoc='center', loc='center')\n",
    "\n",
    "# Adjust table properties\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(8)\n",
    "table.scale(1, 1.5)\n",
    "\n",
    "# Save the table as an image\n",
    "table_image_path = 'table.png'\n",
    "plt.savefig(table_image_path, dpi=300, bbox_inches='tight')\n",
    "plt.close(fig)\n",
    "\n",
    "# Add noise to the image\n",
    "img = Image.open(table_image_path).convert(\"RGB\")  # Ensure the image is in RGB mode\n",
    "img_array = np.array(img)  # Convert to NumPy array for OpenCV processing\n",
    "\n",
    "# Add random dots as noise\n",
    "num_dots = 18000  # Number of dots to add\n",
    "dot_radius =  random.randint(1, 3)  # Radius of the dots\n",
    "#dot_color =  generate_greyscale_color()  # Black dots (R, G, B)\n",
    "dot_color =  (0,0,0)\n",
    "\n",
    "# Add noise dots to the image\n",
    "for _ in range(num_dots):\n",
    "    x = random.randint(0, img_array.shape[1] - 1)  # Random x-coordinate\n",
    "    y = random.randint(0, img_array.shape[0] - 1)  # Random y-coordinate\n",
    "    # Draw a filled circle (dot) at the random position\n",
    "    cv2.circle(img_array, (x, y), dot_radius, dot_color, -1)  # -1 thickness means filled circle\n",
    "\n",
    "# Save the noisy image\n",
    "noisy_image_path = 'img\\\\test1.png'\n",
    "noisy_img = Image.fromarray(img_array)\n",
    "noisy_img.save(noisy_image_path)\n",
    "\n",
    "df_dummy.to_csv(\"dummy.csv\",index=False)\n",
    "\n",
    "print(f\"Noisy table with bigger dots saved as {noisy_image_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "input_image_file = \"img//test1.png\"\n",
    "output_image_file=\"img//test1_processed.png\"\n",
    " \n",
    "def apply_median_filter(image,kernel_size=1):\n",
    "    # Apply a median filter with a 3x3 kernel\n",
    "    filtered_image = cv2.medianBlur(image, kernel_size)\n",
    "    return filtered_image\n",
    "\n",
    "def convert_to_negative(image):\n",
    "    # Convert the image to its negative\n",
    "    negative_image = cv2.bitwise_not(image)\n",
    "    return negative_image\n",
    "\n",
    "def apply_erosion(image, kernel_size=3, iterations=1):\n",
    "    # Create a kernel for erosion\n",
    "    kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "    # Apply erosion to the image\n",
    "    eroded_image = cv2.erode(image, kernel, iterations=iterations)\n",
    "    return eroded_image\n",
    "\n",
    "def apply_dilation(image, kernel_size=3, iterations=1):\n",
    "    # Create a kernel for dilation\n",
    "    kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "    # Apply dilation to the image\n",
    "    dilated_image = cv2.dilate(image, kernel, iterations=iterations)\n",
    "    return dilated_image\n",
    "\n",
    "output_img = cv2.imread(input_image_file)\n",
    "# Example usage:\n",
    "\n",
    "#output_img = convert_to_negative(output_img)\n",
    "#output_img = apply_erosion(img,kernel_size=2,iterations=1)\n",
    "#output_img = apply_dilation(output_img,kernel_size=2,iterations=1)\n",
    "\n",
    "\n",
    "# Thresholding to create a binary image \n",
    "_, binary_image = cv2.threshold(output_img, 127, 255, cv2.THRESH_BINARY) \n",
    " \n",
    "# Define a kernel \n",
    "kernel = np.ones((1, 1), np.uint8) \n",
    " \n",
    "# Apply morphological opening \n",
    "#output_img = cv2.morphologyEx(binary_image, cv2.MORPH_CLOSE, kernel) \n",
    "output_img = cv2.morphologyEx(output_img, cv2.MORPH_OPEN, kernel) \n",
    "output_img = apply_median_filter(output_img, kernel_size=3) \n",
    "\n",
    "cv2.imwrite(output_image_file, output_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img  = cv2.imread(input_image_file)\n",
    "original_height, original_width = img.shape[:2]\n",
    "scale_percent=30\n",
    "# Calculate new dimensions\n",
    "new_width = int(original_width * scale_percent / 100)\n",
    "new_height = int(original_height * scale_percent / 100)\n",
    "    \n",
    "    # Resize the image\n",
    "resized_image = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "cv2.imwrite(resized_image_file, resized_image)    \n",
    "print(resized_image.shape[:2])\n",
    "\n",
    "plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))  # Convert BGR to RGB for correct colors\n",
    "plt.axis('off')  # Hide axes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image size: (1942, 1192, 3)\n",
      "Total tokens output: 1045 Total cost: 0.006152\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "import os\n",
    "import base64\n",
    "from PIL import Image\n",
    "import base64\n",
    "import openai\n",
    "from pydantic import BaseModel\n",
    "import pandas as pd\n",
    "import json\n",
    "import cv2 \n",
    "\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"]=\"\" # Replace with your OpenAI API key\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "\n",
    "client = openai.OpenAI()\n",
    "certainty=\"50%\"\n",
    "\n",
    "SYSTEM_PROMPT = f\"\"\"Act as an OCR assistant. Analyze the provided image and:\n",
    "1. Recognize all visible text in the image as accurately as possible.\n",
    "2. Maintain the original structure and formatting of the text.\n",
    "3. If any words or phrases are unclear, indicate this with [unclear] in your transcription.\n",
    "4. Return the output on json format.\n",
    "5. Replace any character of the text with # if you are certain less than {certainty}\n",
    "6. This is a table all 5 columns have to be in the json structure and have to have values\n",
    "7. Col1 is a list where each element has a format  string / string\n",
    "8. Col2 is a list where each element has a format length max 2\n",
    "9. Col3 is a list where each element is a string\n",
    "10. Col4 is a list where each element is a string of length 9\n",
    "11. Col5 is a list where each element  is a string of length 1\n",
    "12. You should not have empty rows and if you are not cetrain at all add ###\n",
    "Provide only the transcription without any additional comments.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def calculate_match_percentage(string1, string2):\n",
    "    \"\"\"\n",
    "    Calculate the percentage of overlap between two strings.\n",
    "    \n",
    "    Args:\n",
    "        string1 (str): The smaller or substring to compare.\n",
    "        string2 (str): The larger string to compare against.\n",
    "\n",
    "    Returns:\n",
    "        float: Percentage of characters in string1 found in string2.\n",
    "    \"\"\"\n",
    "    # Check if string1 is a substring of string2\n",
    "    if string1 in string2:\n",
    "        return 100.0  # Full match as substring\n",
    "    \n",
    "    # Calculate character-wise matches\n",
    "    match_count = sum(1 for char1, char2 in zip(string1, string2) if char1 == char2)\n",
    "    \n",
    "    # Calculate percentage match\n",
    "    percentage = (match_count / len(string1)) * 100\n",
    "    return percentage\n",
    "\n",
    "\n",
    "def encode_image_to_base64(image_path):\n",
    "    \"\"\"Convert an image file to a base64 encoded string.\"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "\n",
    "class OCRData(BaseModel):\n",
    "    col1: list[str]\n",
    "    col2: list[str]\n",
    "    col3: list[str]\n",
    "    col4: list[str]\n",
    "    col5: list[str]\n",
    "\n",
    "\n",
    "#resize image scale\n",
    "scale_percent=50\n",
    "model_name = \"gpt-4o-mini-2024-07-18\" #gpt-4o-2024-08-06, gpt-4o-mini\n",
    "total_tokens=0\n",
    "\n",
    "# Getting the base64 string\n",
    "img  = cv2.imread(input_image_file)\n",
    "\n",
    "original_height, original_width = img.shape[:2]\n",
    "\n",
    "# Calculate new dimensions\n",
    "new_width = int(original_width * scale_percent / 100)\n",
    "new_height = int(original_height * scale_percent / 100)\n",
    "    \n",
    "# Resize the image\n",
    "resized_image = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "cv2.imwrite(resized_image_file, resized_image)    \n",
    "\n",
    "base64_image = encode_image_to_base64(resized_image_file)\n",
    "\n",
    "response = client.beta.chat.completions.parse(\n",
    "    model=model_name, \n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"\"\"extract the data from the table that has 5 columns in the image.\"\"\",\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"},\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    "      response_format={ \"type\": \"json_object\" }#OCRData,\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "r = json.loads(response.choices[0].message.content)\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(model_name).name\n",
    "\n",
    "for col in [\"col1\",\"col2\",\"col3\",\"col4\",\"col5\"]:\n",
    "    col_tokens = num_tokens_from_string(\" \".join(r[col]),encoding)\n",
    "    total_tokens = total_tokens + col_tokens\n",
    "\n",
    "#depends on the model\n",
    "#price_per_output_token = 10/1000000 \n",
    "print(\"image size:\",resized_image.shape)\n",
    "price_per_output_token = 0.600/1000000 \n",
    "image_cost = 0.005525 #for x=1942, y=1192\n",
    "\n",
    "print(\"Total tokens output:\",total_tokens,\"Total cost:\",total_tokens*price_per_output_token+image_cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = json.loads(response.choices[0].message.content)\n",
    "\n",
    "ai_original_col1 = r[\"col1\"]\n",
    "ai_original_col2 = r[\"col2\"]\n",
    "ai_original_col3 = r[\"col3\"]\n",
    "ai_original_col4 = r[\"col4\"]\n",
    "ai_original_col5 = r[\"col5\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE COUNT:15,0.3\n",
      "FALSE COUNT:35,0.7\n"
     ]
    }
   ],
   "source": [
    "\n",
    "false_count= true_count=0\n",
    "k=3\n",
    "col_name=\"col5\"\n",
    "ai_col=ai_original_col5\n",
    "\n",
    "df_dummy = pd.read_csv(\"dummy.csv\")\n",
    "\n",
    "\n",
    "for i, r in df_dummy.head(len(ai_col)).iterrows():\n",
    "    if k>=0:\n",
    "        string1 =  ai_col[i][:k]\n",
    "        string2 = str(df_dummy[col_name].loc[i])[:k]\n",
    "        condition =string1.startswith(string2)\n",
    "        percentage_match = calculate_match_percentage(string1, string2)\n",
    "\n",
    "    if k<0:\n",
    "        string1 =  ai_col[i][k:]\n",
    "        string2 = str(df_dummy[col_name].loc[i])[k:]\n",
    "        condition =string1.startswith(string2)\n",
    "        percentage_match = calculate_match_percentage(string1, string2)\n",
    "\n",
    "    if condition:\n",
    "        true_count += 1\n",
    "    else:\n",
    "        false_count+= 1\n",
    "\n",
    "print(f\"TRUE COUNT:{true_count},{true_count/len(df_dummy)}\")\n",
    "print(f\"FALSE COUNT:{false_count},{false_count/len(df_dummy)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "col1    3625663720/10972910\n",
       "col2                     30\n",
       "col3           jraysihfhpwb\n",
       "col4              162135727\n",
       "col5                      B\n",
       "Name: 49, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26025\n",
      "76025\n"
     ]
    }
   ],
   "source": [
    "TRUE COUNT:33,0.66\n",
    "FALSE COUNT:16,0.32\n",
    "\n",
    "TRUE COUNT:34,0.68\n",
    "FALSE COUNT:16,0.32\n",
    "\n",
    "\n",
    "50%\n",
    "TRUE COUNT:32,0.64\n",
    "FALSE COUNT:18,0.36\n",
    "\n",
    "30%\n",
    "TRUE COUNT:18,0.36\n",
    "FALSE COUNT:32,0.64\n",
    "\n",
    "\n",
    "\n",
    "Original\n",
    "TRUE COUNT:35,0.7\n",
    "FALSE COUNT:15,0.3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "occasioforecast",
   "language": "python",
   "name": "occasioforecast"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
